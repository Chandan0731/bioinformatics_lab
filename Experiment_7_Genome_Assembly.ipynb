{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2gkENibXbkxu9XSltsVRk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chandan0731/bioinformatics_lab/blob/main/Experiment_7_Genome_Assembly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFwYD8Upuz24",
        "outputId": "b5a9050c-8620-40be-9cba-e92309bc8f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing FastQC and Velvet...\n",
            "Extracting templates from packages: 100%\n",
            "✅ Installation complete.\n",
            "Downloading raw sequencing reads...\n",
            "✅ Files downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 1. Install FastQC (Quality Checker) and Velvet (The Assembler)\n",
        "print(\"Installing FastQC and Velvet...\")\n",
        "!apt-get install fastqc velvet > /dev/null\n",
        "print(\"✅ Installation complete.\")\n",
        "\n",
        "# 2. Download the Raw Sequencing Data (FASTQ files)\n",
        "print(\"Downloading raw sequencing reads...\")\n",
        "!wget -q https://zenodo.org/record/582600/files/mutant_R1.fastq\n",
        "!wget -q https://zenodo.org/record/582600/files/mutant_R2.fastq\n",
        "\n",
        "if os.path.exists(\"mutant_R1.fastq\") and os.path.exists(\"mutant_R2.fastq\"):\n",
        "    print(\"✅ Files downloaded successfully.\")\n",
        "else:\n",
        "    print(\"❌ Download failed. Please try again.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running FastQC on Read 1...\")\n",
        "!fastqc mutant_R1.fastq\n",
        "\n",
        "print(\"Running FastQC on Read 2...\")\n",
        "!fastqc mutant_R2.fastq\n",
        "\n",
        "# List the output files to confirm\n",
        "print(\"\\n--- Output Files ---\")\n",
        "!ls *.html\n",
        "print(\"✅ Quality Check done. You can see the .html reports in the file browser.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdYK9Yi4xXmo",
        "outputId": "43af6e9e-cfd7-450d-a0e7-0e2633ad7989"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running FastQC on Read 1...\n",
            "Started analysis of mutant_R1.fastq\n",
            "Approx 5% complete for mutant_R1.fastq\n",
            "Approx 15% complete for mutant_R1.fastq\n",
            "Approx 20% complete for mutant_R1.fastq\n",
            "Approx 30% complete for mutant_R1.fastq\n",
            "Approx 40% complete for mutant_R1.fastq\n",
            "Approx 45% complete for mutant_R1.fastq\n",
            "Approx 55% complete for mutant_R1.fastq\n",
            "Approx 60% complete for mutant_R1.fastq\n",
            "Approx 70% complete for mutant_R1.fastq\n",
            "Approx 80% complete for mutant_R1.fastq\n",
            "Approx 85% complete for mutant_R1.fastq\n",
            "Approx 95% complete for mutant_R1.fastq\n",
            "Analysis complete for mutant_R1.fastq\n",
            "Running FastQC on Read 2...\n",
            "Started analysis of mutant_R2.fastq\n",
            "Approx 5% complete for mutant_R2.fastq\n",
            "Approx 15% complete for mutant_R2.fastq\n",
            "Approx 20% complete for mutant_R2.fastq\n",
            "Approx 30% complete for mutant_R2.fastq\n",
            "Approx 40% complete for mutant_R2.fastq\n",
            "Approx 45% complete for mutant_R2.fastq\n",
            "Approx 55% complete for mutant_R2.fastq\n",
            "Approx 60% complete for mutant_R2.fastq\n",
            "Approx 70% complete for mutant_R2.fastq\n",
            "Approx 80% complete for mutant_R2.fastq\n",
            "Approx 85% complete for mutant_R2.fastq\n",
            "Approx 95% complete for mutant_R2.fastq\n",
            "Analysis complete for mutant_R2.fastq\n",
            "\n",
            "--- Output Files ---\n",
            "mutant_R1_fastqc.html  mutant_R2_fastqc.html\n",
            "✅ Quality Check done. You can see the .html reports in the file browser.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import shutil\n",
        "\n",
        "# 1. Create a clean directory for the output\n",
        "if os.path.exists(\"assembly_output\"):\n",
        "    shutil.rmtree(\"assembly_output\")\n",
        "os.makedirs(\"assembly_output\")\n",
        "\n",
        "# 2. Run 'velveth' (Hashing)\n",
        "# This builds a \"Hash Table\" (index) of all the k-mers (word fragments)\n",
        "print(\"Step 1: Hashing reads (velveth)...\")\n",
        "!velveth assembly_output 31 -short -separate -fastq mutant_R1.fastq mutant_R2.fastq\n",
        "\n",
        "# 3. Run 'velvetg' (Graph Building)\n",
        "# This connects the fragments into a De Bruijn Graph to build the contigs\n",
        "print(\"Step 2: Building graph (velvetg)...\")\n",
        "!velvetg assembly_output -cov_cutoff auto\n",
        "\n",
        "# 4. View Results\n",
        "print(\"\\n--- ASSEMBLY COMPLETED ---\")\n",
        "result_path = \"assembly_output/contigs.fa\"\n",
        "\n",
        "if os.path.exists(result_path):\n",
        "    print(f\"✅ Assembly successful! Output saved to: {result_path}\")\n",
        "\n",
        "    # Show the top 10 lines of the result\n",
        "    print(\"\\nFirst 10 assembled sequences (Contigs):\")\n",
        "    with open(result_path, 'r') as f:\n",
        "        print(f.read(500)) # Print first 500 characters\n",
        "else:\n",
        "    print(\"❌ Assembly failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_dVYsyYygKh",
        "outputId": "4816d43a-3dbe-429d-e477-37816281e6e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Hashing reads (velveth)...\n",
            "[0.000000] Reading FastQ file mutant_R1.fastq;\n",
            "[0.056853] 12480 sequences found\n",
            "[0.056876] Done\n",
            "[0.056929] Reading FastQ file mutant_R2.fastq;\n",
            "[0.111949] 12480 sequences found\n",
            "[0.111973] Done\n",
            "[0.112068] Reading read set file assembly_output/Sequences;\n",
            "[0.117135] 24960 sequences found\n",
            "[0.142154] Done\n",
            "[0.142186] 24960 sequences in total.\n",
            "[0.142427] Writing into roadmap file assembly_output/Roadmaps...\n",
            "[0.188147] Inputting sequences...\n",
            "[0.188182] Inputting sequence 0 / 24960\n",
            "[0.983871]  === Sequences loaded in 0.795727 s\n",
            "[0.983915] Done inputting sequences\n",
            "[0.983918] Destroying splay table\n",
            "[0.995050] Splay table destroyed\n",
            "Step 2: Building graph (velvetg)...\n",
            "[0.000000] Reading roadmap file assembly_output/Roadmaps\n",
            "[0.045449] 24960 roadmaps read\n",
            "[0.045676] Creating insertion markers\n",
            "[0.048965] Ordering insertion markers\n",
            "[0.067781] Counting preNodes\n",
            "[0.071358] 64223 preNodes counted, creating them now\n",
            "[0.172092] Adjusting marker info...\n",
            "[0.175812] Connecting preNodes\n",
            "[0.213073] Cleaning up memory\n",
            "[0.213207] Done creating preGraph\n",
            "[0.213215] Concatenation...\n",
            "[0.234880] Renumbering preNodes\n",
            "[0.234915] Initial preNode count 64223\n",
            "[0.237305] Destroyed 37924 preNodes\n",
            "[0.237325] Concatenation over!\n",
            "[0.237328] Clipping short tips off preGraph\n",
            "[0.238764] Concatenation...\n",
            "[0.243165] Renumbering preNodes\n",
            "[0.243190] Initial preNode count 26299\n",
            "[0.244802] Destroyed 3832 preNodes\n",
            "[0.244817] Concatenation over!\n",
            "[0.244819] 1986 tips cut off\n",
            "[0.244821] 22467 nodes left\n",
            "[0.245056] Writing into pregraph file assembly_output/PreGraph...\n",
            "[0.315241] Reading read set file assembly_output/Sequences;\n",
            "[0.319960] 24960 sequences found\n",
            "[0.344839] Done\n",
            "[0.399602] Reading pre-graph file assembly_output/PreGraph\n",
            "[0.399685] Graph has 22467 nodes and 24960 sequences\n",
            "[0.430210] Scanning pre-graph file assembly_output/PreGraph for k-mers\n",
            "[0.435484] 434645 kmers found\n",
            "[0.465241] Sorting kmer occurrence table ... \n",
            "[0.590132] Sorting done.\n",
            "[0.590156] Computing acceleration table... \n",
            "[0.633362] Computing offsets... \n",
            "[0.635728] Ghost Threading through reads 0 / 24960\n",
            "[0.636040]  === Ghost-Threaded in 0.000313 s\n",
            "[0.636049] Threading through reads 0 / 24960\n",
            "[1.520164]  === Threaded in 0.884114 s\n",
            "[1.525752] Correcting graph with cutoff 0.200000\n",
            "[1.527385] Determining eligible starting points\n",
            "[1.548361] Done listing starting nodes\n",
            "[1.548393] Initializing todo lists\n",
            "[1.552690] Done with initialization\n",
            "[1.552725] Activating arc lookup table\n",
            "[1.554659] Done activating arc lookup table\n",
            "[1.667947] 10000 / 22467 nodes visited\n",
            "[1.802675] 20000 / 22467 nodes visited\n",
            "[1.846149] Concatenation...\n",
            "[1.846391] Renumbering nodes\n",
            "[1.846397] Initial node count 22467\n",
            "[1.846459] Removed 22097 null nodes\n",
            "[1.846462] Concatenation over!\n",
            "[1.846464] Clipping short tips off graph, drastic\n",
            "[1.846487] Concatenation...\n",
            "[1.846738] Renumbering nodes\n",
            "[1.846750] Initial node count 370\n",
            "[1.846760] Removed 14 null nodes\n",
            "[1.846764] Concatenation over!\n",
            "[1.846770] 356 nodes left\n",
            "[1.846962] Writing into graph file assembly_output/Graph...\n",
            "[1.888154] Measuring median coverage depth...\n",
            "[1.888251] Median coverage depth = 15.268604\n",
            "[1.888276] Removing contigs with coverage < 7.634302...\n",
            "[1.888341] Concatenation...\n",
            "[1.892338] Renumbering nodes\n",
            "[1.892365] Initial node count 356\n",
            "[1.892380] Removed 328 null nodes\n",
            "[1.892386] Concatenation over!\n",
            "[1.892393] Concatenation...\n",
            "[1.892399] Renumbering nodes\n",
            "[1.892404] Initial node count 28\n",
            "[1.892409] Removed 0 null nodes\n",
            "[1.892413] Concatenation over!\n",
            "[1.892418] Clipping short tips off graph, drastic\n",
            "[1.892425] Concatenation...\n",
            "[1.892434] Renumbering nodes\n",
            "[1.892438] Initial node count 28\n",
            "[1.892443] Removed 0 null nodes\n",
            "[1.892448] Concatenation over!\n",
            "[1.892453] 28 nodes left\n",
            "[1.892459] WARNING: NO EXPECTED COVERAGE PROVIDED\n",
            "[1.892464] Velvet will be unable to resolve any repeats\n",
            "[1.892469] See manual for instructions on how to set the expected coverage parameter\n",
            "[1.892474] Concatenation...\n",
            "[1.892480] Renumbering nodes\n",
            "[1.892485] Initial node count 28\n",
            "[1.892490] Removed 0 null nodes\n",
            "[1.892496] Concatenation over!\n",
            "[1.892501] Removing reference contigs with coverage < 7.634302...\n",
            "[1.892542] Concatenation...\n",
            "[1.892548] Renumbering nodes\n",
            "[1.892553] Initial node count 28\n",
            "[1.892559] Removed 0 null nodes\n",
            "[1.892564] Concatenation over!\n",
            "[1.892903] Writing contigs into assembly_output/contigs.fa...\n",
            "[1.918574] Writing into stats file assembly_output/stats.txt...\n",
            "[1.918864] Writing into graph file assembly_output/LastGraph...\n",
            "[1.950834] Estimated Coverage cutoff = 7.634302\n",
            "Final graph has 28 nodes and n50 of 30350, max 36533, total 178563, using 0/24960 reads\n",
            "\n",
            "--- ASSEMBLY COMPLETED ---\n",
            "✅ Assembly successful! Output saved to: assembly_output/contigs.fa\n",
            "\n",
            "First 10 assembled sequences (Contigs):\n",
            ">NODE_1_length_36533_cov_15.071278\n",
            "CAATGGTTTCATCCAAAGCTTAAAAGATGATAAAGCAGAAGGTCCCTATGTAGCAATTTC\n",
            "TAAAGTTGGAAAAGGTAAAGCAGCATTTATCGGTGATTCATCACTTGTGGAAGATAGTTC\n",
            "GCCCAAATATGTGAGAGAAGATAATGGAGAAAAGAAGAAAACATATGATGGTTTTAAAGA\n",
            "ACAAGACAACGGTAAGCTATTAAATAATATAACAGCTTGGATGTCTAAAGATAATGATGG\n",
            "GAAATCACTTAAGGCGAGTGGCCTAACATTAGATACAAAGACTAAGTTGCTTGATTTTGA\n",
            "ACGACCAGAGCGTTCAACTGAGCCTGAAAAAGAGCCATGGTCACAACCGCCGAGTGGTTA\n",
            "TAAATGCTATGACCCAACAACATTTAAAGCAGGTAGTTATGGCAGTGAAGAAGGCGCGGA\n",
            "TCCTCAGCCAAACACACCAGATGGTCATACGCCACCAA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 4: Assembly Statistics and Validation\n",
        "# We calculate metrics (Contig count, N50, Max Length) to prove the assembly worked.\n",
        "\n",
        "# 1. Install Biopython (Fixes 'No module named Bio' error)\n",
        "!pip install biopython\n",
        "\n",
        "from Bio import SeqIO\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "contig_file = \"assembly_output/contigs.fa\"\n",
        "\n",
        "# Check if file exists before analyzing\n",
        "if not os.path.exists(contig_file):\n",
        "    print(f\"❌ Error: The file '{contig_file}' was not found.\")\n",
        "    print(\"Please make sure you ran Block 3 successfully first.\")\n",
        "else:\n",
        "    print(f\"\\nAnalyzing Assembly Results from: {contig_file}\\n\")\n",
        "\n",
        "    # 2. Read the contigs\n",
        "    contigs = list(SeqIO.parse(contig_file, \"fasta\"))\n",
        "    lengths = [len(c.seq) for c in contigs]\n",
        "    lengths.sort(reverse=True) # Sort from biggest to smallest\n",
        "\n",
        "    if len(lengths) > 0:\n",
        "        # 3. Calculate Statistics\n",
        "        total_bases = sum(lengths)\n",
        "        num_contigs = len(lengths)\n",
        "        max_len = lengths[0]\n",
        "        min_len = lengths[-1]\n",
        "\n",
        "        # Calculate N50 (Standard assembly quality metric)\n",
        "        cumsum = np.cumsum(lengths)\n",
        "        n50_idx = np.searchsorted(cumsum, total_bases / 2)\n",
        "        n50 = lengths[n50_idx]\n",
        "\n",
        "        # 4. Print the \"Report Card\"\n",
        "        print(\"=\"*40)\n",
        "        print(\"      GENOME ASSEMBLY REPORT\")\n",
        "        print(\"=\"*40)\n",
        "        print(f\"Total Contigs Found:   {num_contigs}\")\n",
        "        print(f\"Total Genome Length:   {total_bases} bp\")\n",
        "        print(f\"Largest Contig:        {max_len} bp\")\n",
        "        print(f\"Smallest Contig:       {min_len} bp\")\n",
        "        print(f\"N50 Score:             {n50}\")\n",
        "        print(\"=\"*40)\n",
        "\n",
        "        # 5. Show the actual Sequences (Evidence)\n",
        "        print(\"\\nTop 5 Longest Assembled Sequences:\")\n",
        "        for i in range(min(5, len(contigs))):\n",
        "            print(f\"\\n>Contig_{i+1} (Length: {len(contigs[i].seq)} bp)\")\n",
        "            # Print first 100 bases only\n",
        "            print(str(contigs[i].seq)[:100] + \"...\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ valid contigs file found, but it is empty.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lak0Y_CByz9S",
        "outputId": "8427d9f2-c290-46d6-c629-ae7507593aa6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.86-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (2.0.2)\n",
            "Downloading biopython-1.86-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m143.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.86\n",
            "\n",
            "Analyzing Assembly Results from: assembly_output/contigs.fa\n",
            "\n",
            "========================================\n",
            "      GENOME ASSEMBLY REPORT\n",
            "========================================\n",
            "Total Contigs Found:   20\n",
            "Total Genome Length:   179090 bp\n",
            "Largest Contig:        36563 bp\n",
            "Smallest Contig:       61 bp\n",
            "N50 Score:             30380\n",
            "========================================\n",
            "\n",
            "Top 5 Longest Assembled Sequences:\n",
            "\n",
            ">Contig_1 (Length: 36563 bp)\n",
            "CAATGGTTTCATCCAAAGCTTAAAAGATGATAAAGCAGAAGGTCCCTATGTAGCAATTTCTAAAGTTGGAAAAGGTAAAGCAGCATTTATCGGTGATTCA...\n",
            "\n",
            ">Contig_2 (Length: 790 bp)\n",
            "GGTTCTGTTGCAAAGTAAAAAAATATAGCTAACCACTAATTTATCATGTCAGTGTTCGCTTAACTTGCTAGCATGATGCTAATTTCGTGGCATGGCGAAA...\n",
            "\n",
            ">Contig_3 (Length: 34959 bp)\n",
            "ATACTATAAATTCAACTTTGCAACAGAACCTTCTACATTAAATACTTTGTCAATGAGATCATCTACATCTTTAAATTTAGAATAATTTGCATATGGATCT...\n",
            "\n",
            ">Contig_4 (Length: 30380 bp)\n",
            "AAAGCAATCCTAAGTAAAATTGCAGATAAGGGGTACAGAAAAACTAGACTTGATTACAAAATGGAGCTTGGGACATAAATGATTTTTTAAAAATGAGATG...\n",
            "\n",
            ">Contig_5 (Length: 17420 bp)\n",
            "GGCTGGTTTTATTGGGTCACATTTAGTAGATGATTTGCAACAAGATTATGATGTTTATGTTCTAGATAACTATAGAACAGGTAAACGAGAAAATATTAAA...\n"
          ]
        }
      ]
    }
  ]
}